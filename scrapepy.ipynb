{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tutorial used: https://realpython.com/python-web-scraping-practical-introduction/#scrape-and-parse-text-from-websites\n",
    "\n",
    "- Python standard library urllib which has tools for working with URLs\n",
    "\n",
    "- The urlopen module can open urls.\n",
    "\n",
    "- The module re will be used to utilize regular expressions to find data in the html.\n",
    "\n",
    "- **Warning from tutorial states you can get banned for scraping web data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set the URL.\n",
    "- Use the urlopen module open the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://olympus.realpython.org/profiles/aphrodite\"\n",
    "page = urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decode() returns a sequence of bytes which is a string of html text without any formatting.\n",
    "- Decode method defaults to utf-8; errors='strict,ignore,or replace' possible to handle errors, not checked by default.\n",
    "- When outputting raw data using print, html_bytes is just a long string while html is formatted nicely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_bytes = page.read()\n",
    "html = html_bytes.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **First way to extract content from web page using html methods.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This example extracts the word Aphrodite from example web page at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aphrodite\n"
     ]
    }
   ],
   "source": [
    "# finding start index of substring example using html\n",
    "start_index = html.find(\"Aphrodite\")\n",
    "# get length of target word\n",
    "target_word_len = len(\"Aphrodite\")\n",
    "# find ending of word which is the title\n",
    "end_index = html.find(\"</title>\")\n",
    "#extract target word from html\n",
    "target_word = html[start_index:end_index]\n",
    "print(target_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Second way to extract content from web page using regular expressions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of times the letter b appears in the html using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns array of all b's found\n",
    "re.findall(\"b\",html)\n",
    "# return how many b's we found\n",
    "len(re.findall(\"b\",html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all instances of \\<br>\\ html tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns array of all <br> found\n",
    "re.findall(\"<br>\",html)\n",
    "# return how many <br> we found\n",
    "len(re.findall(\"<br>\",html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Practical Example: Get all products from an example online store.**\n",
    "Previous regex pattern - title=\"[A-Z])\\w+.+\"\n",
    "\n",
    "regex pattern - title=\\\"[A-Z].+\\\"\n",
    "\n",
    "All products started in the html code with title=\". The \\\\ in \\\\\" is to escape the \" quotes which starts the title. [A-Z] is to look for the first character in a capitalized title of the product. . looks for any character except line breaks. The + is to search for # of characters >= 1. The last \\\\\" is the end of the title with the \\ escaping the \" end quote.\n",
    "\n",
    "reg ex cheat sheet used: https://www.rexegg.com/regex-quickstart.html\n",
    "\n",
    "regex live tester used: https://regexr.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title=\"Asus ROG Strix GL753VE-GC096T\"',\n",
       " 'title=\"Acer Aspire 3 A315-31 Black\"',\n",
       " 'title=\"Dell Vostro 15\"']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load page and decode\n",
    "url_practice = \"https://webscraper.io/test-sites/e-commerce/static\"\n",
    "page_practice = urlopen(url_practice)\n",
    "html_practice_bytes = page_practice.read()\n",
    "html_practice = html_practice_bytes.decode()\n",
    "\n",
    "# using regular expressions to find all product names\n",
    "re.findall('(title=\\\"[A-Z].+\\\")',html_practice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
